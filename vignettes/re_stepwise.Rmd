---
title: "re_stepwise"
author: "Noah Suter"
date: "`r Sys.Date()`"
output: html_document
---
# AGDS Report

## Report Exercise 4

### Preparing the data


```{r results='hide'}
list.files('../data') #listing the files to find the right data
```

```{r results='hide', message=FALSE}
half_hourly_fluxes <- readr::read_csv("../data/df_for_stepwise_regression.csv") # reading the data into R
```

```{r}
visdat::vis_miss(half_hourly_fluxes) #checking for missing values
```

We can see that quite a few rows contain missing values. It will be important to keep that in mind for the interpretation of the results and for the creation of the model. For creating a model I chose to handle the missing data by deleting the rows containing missing values.


```{r results='hide'}
summary(half_hourly_fluxes) #looking at the exact number of missing values (NA) per row
```

```{r warning=FALSE, message=FALSE}
half_hourly_fluxes_new_order <- dplyr::select(half_hourly_fluxes,`GPP_NT_VUT_REF`, everything()) #moving the column of the response variable (GPP) to position one
```

```{r warning=FALSE, message=FALSE}
half_hourly_fluxes_clean <- stats::na.omit(half_hourly_fluxes_new_order)
```


## Stepwsise forward regression - bivariate models in a loop

```{r results='hide'}

# Defining the response variable
response_var <- "GPP_NT_VUT_REF"

# Creating a list to store the results
results <- list()

# Loop through all predictor variables to build all the bivariate models
for (predictor in c("none", "siteid", "TIMESTAMP", "TA_F", "SW_IN_F", "LW_IN_F", "VPD_F", 
                    "PA_F", "P_F", "WS_F", "TA_F_MDS", "SW_IN_F_MDS", "LW_IN_F_MDS",
                    "VPD_F_MDS", "CO2_F_MDS", "PPFD_IN", "USTAR")) {
  
  if (predictor == "none") {
    # Building a empty model with just the intercepte
    formula_string <- paste0(response_var, " ~ 1")
  } else {
    # Building the model with the corresponsding predictor
    formula_string <- paste0(response_var, " ~ ", predictor)
  }
  
  # Creating the formula object
  formula <- as.formula(formula_string)
  
  # Fit the linear model
  model <- lm(formula, data = half_hourly_fluxes_clean)
  
  # Store the results of the model in the list
  results[[predictor]] <- c(formula_string, AIC(model), summary(model)$r.squared, summary(model)$adj.r.squared)
}
```

```{r warning=FALSE, message=FALSE}
# Converting the list of results into a data frame
results_bivariate <- as.data.frame(do.call(rbind, results))

# Renaming the columns
colnames(results_bivariate) <- c("formula", "AIC", "r_squared", "adj_r_squared")

# Converting the AIC to be numeric
results_bivariate$AIC <- as.numeric(results_bivariate$AIC)

# Sort the data frame by AIC value in ascending order
results_bivariate <- results_bivariate[order(results_bivariate$AIC), ]

# Print the results (of the 10 best models)
results_bivariate[1:10,]
```


Here we get the bivariate models already sorted ascending by the AIC. Therefore the best bivariate model is to find on top. As the lowest AIC is the best, this predictor should be used. In this case it would be PPFD_IN. As <none> is not the best option, it makes sense to continue to improve the model by doing a stepwise forward regression. Additionally, One can see that the R squared as well as the adjusted R squared is increasing if higher up (=better AIC). That makes sense as the model is better for this data if there is a higher R squared. The higher the adjusted R squared, the higher the Generalizability. Therefore it makes sense that the best model (highest AIC) has the highest adjusted R squared as well. It would be possible that the best model does not have the highest R squared, but in this case the highest R squared correlates with the lowest AIC. (It would make sense as the r squared just looks at the best model for this data but not for new data)

## Plot of the best bivariate model
```{r warning=FALSE, message=FALSE}
library(ggplot2)

ggplot(half_hourly_fluxes_clean, aes(x = PPFD_IN , y = GPP_NT_VUT_REF)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, linewidth = 0.5, col="red") +
  labs(x = "PPFD_IN", y = "GPP_NT_VUT_REF",
       title = "Regression between GGP and PPFD") #plotting the result of the regression with one predictor
```

One can suspect a linear correlation between these two values. But is is not possible to state anything about the dependence of these two values as they could have a correlation per coincidence. At the same time one can see that the GPP_NT_VUT_REF values are not described perfectly by just using a linear regression model with the only predictor being PPFD_IN. Therefore it makes sense to continue with a stepwise approach to try to improve the model.

## Full stepwise forward regression with a loop

```{r warning=FALSE, message=FALSE}
# Defining the response variable
response_var <- "GPP_NT_VUT_REF"
# Creating a vector to store the selected predictors
selected_predictors <- c()
# Creating a list to store the models
models <- list()
# Loop through the predictors
for (i in 1:ncol(half_hourly_fluxes_clean)) {
  
  # Creating a variable to store the best predictor
  best_predictor <- NULL
  
  # Creating a variable to store the lowest AIC
  lowest_aic <- Inf
  
  # Loop through the remaining predictors
  for (j in setdiff(names(half_hourly_fluxes_clean)[-1], selected_predictors)) {
    
    # Create a model for the current predictor
    candidate_formula <- as.formula(paste(response_var, "~", paste(c(selected_predictors, j), collapse = "+")))
    
    # Fit a linear model and adding the current predictor
    candidate_lm <- lm(candidate_formula, data = half_hourly_fluxes_clean)
    
    # Check if the AIC is lower than the current lowest AIC
    if (AIC(candidate_lm) < lowest_aic) {
      best_predictor <- j
      lowest_aic <- AIC(candidate_lm)
    }
    
    # Store the model
    models[[paste(c(selected_predictors, j), collapse = "+")]] <- candidate_lm
  }
  
  # Add the best predictor to the selected predictors
  selected_predictors <- c(selected_predictors, best_predictor)
  
  
}
```

```{r warning=FALSE, message=FALSE}

# creating a data frame to store the model statistics
model_stats <- data.frame(Model = character(),
                           AIC = numeric(),
                           Adj_R2 = numeric(),
                           R2 = numeric(),
                           stringsAsFactors = FALSE)
# Loop through the models and extract the statistics
for (i in seq_along(models)) {
  
  # Extract the formula of the model and the AIC
  model_formula <- formula(models[[i]])
  model_aic <- AIC(models[[i]])
  
  # Extracting the summary of the model and extracting the R-squared and adjusted R-squared
  model_summary <- summary(models[[i]])
  model_adj_r2 <- summary(models[[i]])$adj.r.squared
  model_r2 <- summary(models[[i]])$r.squared
  
  # Add the model statistics to the data frame
  model_stats <- rbind(model_stats, data.frame(Model = as.character(model_formula),
                                               AIC = model_aic,
                                               Adj_R2 = model_adj_r2,
                                               R2 = model_r2,
                                               stringsAsFactors = FALSE))
}
```



```{r warning=FALSE, message=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(base, warn.conflicts = FALSE)

# Group by Formula and summarize 
dataframe_model_values <- model_stats %>%
  group_by(Model) %>%
  summarize(Predictors = paste(Model, collapse = " "),
            AIC = first(AIC),
            Adj_R2= first(Adj_R2),
            R2 = first(R2))
dataframe_model_values[1] <- NULL
```

```{r warning=FALSE, message=FALSE}
# Sort the model statistics data frame by ascending AIC values
dataframe_model_values <- dataframe_model_values[order(dataframe_model_values$AIC), ]
# Print the top row of the model statistics data frame to extract the best model
cat("Best model based on AIC:\n")
print(dataframe_model_values[1, ])
```
The choice of the model makes sense as the lowest AIC is being chosen (the model with the lowest AIC is the best model). It as well makes sense that it stopped after the predictor P_F. Because the model had better AIC values (lower AIC) if no more predictors were added. Additionaly one can see that the highest r squared cannot be found within the best model. This is the case as the r squared just states the best model for this exact data. the adjusted R squared contains the model that has the best generalizabiliy and therfore can be used for new data as well (with the same response variable and predictors. In the end the step function extracts the model with the lowest AIC and the best model is chosen by this value. Therefore the AIC value determines the best model in the end.
```{r warning=FALSE, message=FALSE}
library(tidyverse, warn.conflicts = FALSE)
library(psych, warn.conflicts = FALSE)

pairs.panels(half_hourly_fluxes_clean[,c("PPFD_IN", "siteid", "LW_IN_F", "VPD_F_MDS", "TA_F_MDS","SW_IN_F", "WS_F", "USTAR",  "VPD_F", "CO2_F_MDS", "PA_F", "TIMESTAMP", "P_F")], method= "spearman", lm=TRUE)
```

## Full stepwise regression with the function step (to onfirm the results of the loop)

```{r results='hide', message=FALSE}
FitStart <- lm(GPP_NT_VUT_REF ~ 1, data = half_hourly_fluxes_clean)
FitStart #Start with an empty model (just intercept)
```

```{r results='hide', message=FALSE}
FitAll <- lm(GPP_NT_VUT_REF ~ ., data = half_hourly_fluxes_clean)
FitAll # creating a model with all the predictors
stats::formula(FitAll) #printing the full formula
```

```{r error=TRUE, warning=FALSE, results='hide'}
model_step <- stats::step(FitStart, direction = "forward", scope = formula(FitAll)) # doing the stepwise forward regression
```

```{r warning=FALSE, message=FALSE}
stats::formula(model_step)
```
One can see that the result is the same as the result achieved by the loop before. This shows that the loop worked properly. 


## other optionsto handle the missing data - Imputing the data

As we deleted the missing values, we now have a impact on the quality of the data as almost 2/3 of the rows were deleted. Therefore on could try another option of handling missing data. Another option would be to Impute the data. There one possibility would be to impute the mean, but a better option is to work with mice and run a iterativ process that predicts what the missing values could be based on the values that are not missing. There we can pool the best result and then do a stepwise forward regression with this imputed data. I'm going to show one possibility but will not let the code evaluate as it could take some time to knit that way.$

```{r results='hide', warning=FALSE, message=FALSE}
mice::md.pattern(half_hourly_fluxes) #checking the pattern of the missing data
```

```{r warning=FALSE, eval=FALSE}
imp_data <- mice::mice(half_hourly_fluxes, m = 57 , maxit = 15, seed = 12345, print = FALSE) #setting the mice options and run the mice function
```

```{r results='hide', eval=FALSE}
imp_data #checking the used methods
```


```{r eval=FALSE}
plot(imp_data) #checking if convergence was achieved
```
afterwards one could run the stepwise forward regression with the imputed data and then compare the outcome with the other model(the one based on the dataframe where the missing values have been deleted). Then one could check which model is better and makes more sense. But as the mice function would need too long to knit i won't to the stepwise forward regression.







