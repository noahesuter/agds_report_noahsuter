---
title: "re_ml_02"
author: "Noah Suter"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: yes
---

# AGDS Report

## Report Exercise 6

### Loading the data

```{r results='hide'}
list.files('../data') #listing the files to find the right data
```


### Reading and Cleaning the Davos dataset


```{r}
library(lubridate)
library(dplyr)
FLX_Dav <- readr::read_csv("../data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv")|> # reading the data for Davos into R   
  
  # select only the variables we are interested in
  dplyr::select(TIMESTAMP,
                GPP_NT_VUT_REF,    # the target
                ends_with("_QC"),  # quality control info
                ends_with("_F"),   # includes all all meteorological covariates
                -contains("JSB")   # weird useless variable
                ) |>

  # convert to a nice date object
  dplyr::mutate(TIMESTAMP = lubridate::ymd(TIMESTAMP)) |>

  # set all -9999 to NA
  mutate(across(where(is.numeric), ~na_if(., -9999))) |> #deleting all values -9999
 
  
  # retain only data based on >=80% good-quality measurements
  # overwrite bad data with NA (not dropping rows)
  dplyr::mutate(GPP_NT_VUT_REF = ifelse(NEE_VUT_REF_QC < 0.8, NA, GPP_NT_VUT_REF),
                TA_F           = ifelse(TA_F_QC        < 0.8, NA, TA_F),
                SW_IN_F        = ifelse(SW_IN_F_QC     < 0.8, NA, SW_IN_F),
                LW_IN_F        = ifelse(LW_IN_F_QC     < 0.8, NA, LW_IN_F),
                VPD_F          = ifelse(VPD_F_QC       < 0.8, NA, VPD_F),
                PA_F           = ifelse(PA_F_QC        < 0.8, NA, PA_F),
                P_F            = ifelse(P_F_QC         < 0.8, NA, P_F),
                WS_F           = ifelse(WS_F_QC        < 0.8, NA, WS_F)) |> 

  # drop QC variables (no longer needed)
  dplyr::select(-ends_with("_QC"))
```



### Reading and Cleaning the Laegern dataset

```{r}
library(lubridate)
library(dplyr)
FLX_Lae <- readr::read_csv("../data/FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv") |> # reading the data for Laegern into R   
  
  # select only the variables we are interested in
  dplyr::select(TIMESTAMP,
                GPP_NT_VUT_REF,    # the target
                ends_with("_QC"),  # quality control info
                ends_with("_F"),   # includes all all meteorological covariates
                -contains("JSB")   # weird useless variable
                ) |>

  # convert to a nice date object
  dplyr::mutate(TIMESTAMP = lubridate::ymd(TIMESTAMP)) |>

  # set all -9999 to NA
  mutate(across(where(is.numeric), ~na_if(., -9999))) |> #deleting all values -9999
 
  
  # retain only data based on >=80% good-quality measurements
  # overwrite bad data with NA (not dropping rows)
  dplyr::mutate(GPP_NT_VUT_REF = ifelse(NEE_VUT_REF_QC < 0.8, NA, GPP_NT_VUT_REF),
                TA_F           = ifelse(TA_F_QC        < 0.8, NA, TA_F),
                SW_IN_F        = ifelse(SW_IN_F_QC     < 0.8, NA, SW_IN_F),
                LW_IN_F        = ifelse(LW_IN_F_QC     < 0.8, NA, LW_IN_F),
                VPD_F          = ifelse(VPD_F_QC       < 0.8, NA, VPD_F),
                PA_F           = ifelse(PA_F_QC        < 0.8, NA, PA_F),
                P_F            = ifelse(P_F_QC         < 0.8, NA, P_F),
                WS_F           = ifelse(WS_F_QC        < 0.8, NA, WS_F)) |> 

  # drop QC variables (no longer needed)
  dplyr::select(-ends_with("_QC"))
```


### Splitting the data

```{r}
# Data splitting for Dav with a 80/20 split
set.seed(1982)  # made for reproducibility
split <- rsample::initial_split(FLX_Dav, prop = 0.8)
FLX_Dav_train<- rsample::training(split)
FLX_Dav_test <- rsample::testing(split)
```

```{r}
# Data splitting for Lae with a 80/20 split
set.seed(1982)  # made for reproducibility
split <- rsample::initial_split(FLX_Lae, prop = 0.8)
FLX_Lae_train<- rsample::training(split)
FLX_Lae_test <- rsample::testing(split)
```


### Looking for missing values and removing missing values if needed
I chose to delete the missing values before using the caret function, as the caret function would have removed the NA anyways.
```{r}
visdat::vis_miss(FLX_Dav_test, warn_large_data = FALSE) #checking for missing values in the Davos test set
```

```{r}
visdat::vis_miss(FLX_Dav_train, warn_large_data = FALSE) #checking for missing values in the Davos train set
```

```{r}
visdat::vis_miss(FLX_Lae_test, warn_large_data = FALSE) #checking for missing values in the Laegern test set
```

```{r}
visdat::vis_miss(FLX_Lae_train, warn_large_data = FALSE) #checking for missing values in the Laegern train set
```
There are a lot of missing values in all of the datasets. One can see that there are only NA in P_F for the Laegern datasets. That means that one cannot just delete all the rows containing missing values, as all rows contain missing values. I decided to delete the column P_F. Afterwards i delete all the rows that still contain missing values. As of information of the exercise 9 (one before this exercise), the column LW_IN_F has a lot of missing values (at least within the Davos dataset) and is not decisive for the predicted value. And as the same value should be predicted in this exercise, i decided to delete this column out of all the datasets.


