---
title: "re_ml_02"
author: "Noah Suter"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: yes
---

# AGDS Report

## Report Exercise 6

### Loading the data

```{r results='hide'}
list.files('../data') #listing the files to find the right data
```


### Reading and Cleaning the Davos dataset

```{r}
source("../functions/large_files_ex_6.R") #loading all the large code chunks form another .R file
```









### Looking for missing values
I chose to delete the missing values before using the caret function, as the caret function would have removed the NA anyways.
```{r}
visdat::vis_miss(FLX_Dav_test, warn_large_data = FALSE) #checking for missing values in the Davos test set
```

```{r}
visdat::vis_miss(FLX_Dav_train, warn_large_data = FALSE) #checking for missing values in the Davos train set
```

```{r}
visdat::vis_miss(FLX_Lae_test, warn_large_data = FALSE) #checking for missing values in the Laegern test set
```

```{r}
visdat::vis_miss(FLX_Lae_train, warn_large_data = FALSE) #checking for missing values in the Laegern train set
```
There are a lot of missing values in all of the datasets. One can see that there are only NA in P_F for the Laegern datasets. That means that one cannot just delete all the rows containing missing values, as all rows contain missing values. I decided to delete the column P_F. Afterwards i delete all the rows that still contain missing values. As of information of the exercise 9 (one before this exercise), the column LW_IN_F has a lot of missing values (at least within the Davos dataset) and is not decisive for the predicted value. And as the same value should be predicted in this exercise, i decided to delete this column out of all the datasets.





### Within-site validation for Davos models
```{r}
eval_model(mod = caret_dav_train_knn, df_train = FLX_Dav_train, df_test = FLX_Dav_test) # within-site validation knn model davos
```

```{r}
eval_model(mod = caret_dav_train_lm, df_train = FLX_Dav_train, df_test = FLX_Dav_test) #within site validation for Davos lm model 
```


### Within-site validation for Laegern models
```{r}
eval_model(mod = caret_Lae_train_knn, df_train = FLX_Lae_train, df_test = FLX_Lae_test) #within-site validation laegern knn model 
```
```{r}
eval_model(mod = caret_Lae_train_lm, df_train = FLX_Lae_train, df_test = FLX_Lae_test) #within-site validation of Laegern lm model 
```

### Across site validation for Davos models 

```{r}
eval_model(mod = caret_dav_train_knn, df_train = FLX_Dav_train, df_test = FLX_Lae_test) # across-site validation for Davos knn model
```

```{r}
eval_model(mod = caret_dav_train_lm, df_train = FLX_Dav_train, df_test = FLX_Lae_test) # across-site validation for davos lm model
```
### Across site validation for Laegern models

```{r}
eval_model(mod = caret_Lae_train_knn, df_train = FLX_Lae_train, df_test = FLX_Dav_test) #across-site validation for Laegern knn model
```

```{r}
eval_model(mod = caret_Lae_train_lm, df_train = FLX_Lae_train, df_test = FLX_Dav_test) # Across-site validation for Laegern lm model
```

### Training a knn model with the pooled dataset
As only one model should be trained, i chose to do the knn model as it is a bit more prone to overfitting and i therefore hope for more generalisable results.



### within site evaluation of the pooled data
```{r}
eval_model(mod = caret_combined_train_knn, df_train = bind_FLX_train, df_test = bind_FLX_test) #within site validation for the knn model of the pooled data
```



