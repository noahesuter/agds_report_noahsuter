---
title: "re_ml_02"
author: "Noah Suter"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: yes
---

# AGDS Report

## Report Exercise 6

### Loading the data

```{r results='hide'}
list.files('../data') #listing the files to find the right data
```


### Reading and Cleaning the Davos dataset

```{r}
source("../functions/large_files_ex_6.R") #loading all the large code chunks form another .R file
```




### Reading and Cleaning the Laegern dataset

```{r}
library(lubridate)
library(dplyr)
FLX_Lae <- readr::read_csv("../data/FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv") |> # reading the data for Laegern into R   
  
  # select only the variables we are interested in
  dplyr::select(TIMESTAMP,
                GPP_NT_VUT_REF,    # the target
                ends_with("_QC"),  # quality control info
                ends_with("_F"),   # includes all all meteorological covariates
                -contains("JSB")   # weird useless variable
                ) |>

  # convert to a nice date object
  dplyr::mutate(TIMESTAMP = lubridate::ymd(TIMESTAMP)) |>

  # set all -9999 to NA
  mutate(across(where(is.numeric), ~na_if(., -9999))) |> #deleting all values -9999
 
  
  # retain only data based on >=80% good-quality measurements
  # overwrite bad data with NA (not dropping rows)
  dplyr::mutate(GPP_NT_VUT_REF = ifelse(NEE_VUT_REF_QC < 0.8, NA, GPP_NT_VUT_REF),
                TA_F           = ifelse(TA_F_QC        < 0.8, NA, TA_F),
                SW_IN_F        = ifelse(SW_IN_F_QC     < 0.8, NA, SW_IN_F),
                LW_IN_F        = ifelse(LW_IN_F_QC     < 0.8, NA, LW_IN_F),
                VPD_F          = ifelse(VPD_F_QC       < 0.8, NA, VPD_F),
                PA_F           = ifelse(PA_F_QC        < 0.8, NA, PA_F),
                P_F            = ifelse(P_F_QC         < 0.8, NA, P_F),
                WS_F           = ifelse(WS_F_QC        < 0.8, NA, WS_F)) |> 

  # drop QC variables (no longer needed)
  dplyr::select(-ends_with("_QC"))
```


### Splitting the data

```{r}
# Data splitting for Dav with a 80/20 split
set.seed(1982)  # made for reproducibility
split <- rsample::initial_split(FLX_Dav, prop = 0.8)
FLX_Dav_train<- rsample::training(split)
FLX_Dav_test <- rsample::testing(split)
```

```{r}
# Data splitting for Lae with a 80/20 split
set.seed(1982)  # made for reproducibility
split <- rsample::initial_split(FLX_Lae, prop = 0.8)
FLX_Lae_train<- rsample::training(split)
FLX_Lae_test <- rsample::testing(split)
```


### Looking for missing values
I chose to delete the missing values before using the caret function, as the caret function would have removed the NA anyways.
```{r}
visdat::vis_miss(FLX_Dav_test, warn_large_data = FALSE) #checking for missing values in the Davos test set
```

```{r}
visdat::vis_miss(FLX_Dav_train, warn_large_data = FALSE) #checking for missing values in the Davos train set
```

```{r}
visdat::vis_miss(FLX_Lae_test, warn_large_data = FALSE) #checking for missing values in the Laegern test set
```

```{r}
visdat::vis_miss(FLX_Lae_train, warn_large_data = FALSE) #checking for missing values in the Laegern train set
```
There are a lot of missing values in all of the datasets. One can see that there are only NA in P_F for the Laegern datasets. That means that one cannot just delete all the rows containing missing values, as all rows contain missing values. I decided to delete the column P_F. Afterwards i delete all the rows that still contain missing values. As of information of the exercise 9 (one before this exercise), the column LW_IN_F has a lot of missing values (at least within the Davos dataset) and is not decisive for the predicted value. And as the same value should be predicted in this exercise, i decided to delete this column out of all the datasets.

### Deleting the column LW_IN_F

```{r}
FLX_Dav_test$LW_IN_F <- NULL #deleting the column LW_IN_F in Davos test set
```

```{r}
FLX_Dav_train$LW_IN_F <- NULL #deleting the column LW_IN_F in Davos train set
```

```{r}
FLX_Lae_test$LW_IN_F <- NULL #deleting the column LW_IN_F in Laegern test set
```

```{r}
FLX_Lae_train$LW_IN_F <- NULL #deleting the column LW_IN_F in Laegern train test
```

### Deleting the column P_F 
```{r}
FLX_Lae_test$P_F <- NULL #deleting the column P_F in Laegern test set
```

```{r}
FLX_Lae_train$P_F <- NULL #deleting the column P_F in Laegern train set
```

```{r}
FLX_Dav_test$P_F <- NULL #deleting the column P_F in Davos test set
```

```{r}
FLX_Dav_train$P_F <- NULL #deleting the column P_F in Davos train set
```

### Deleting the rows containing missing values
```{r}
FLX_Dav_test<- stats::na.omit(FLX_Dav_test) #deleting all the rows with missing values in Davos test set
```

```{r}
FLX_Dav_train<- stats::na.omit(FLX_Dav_train) #deleting all the rows with missing values in Davos train set
```

```{r}
FLX_Lae_test<- stats::na.omit(FLX_Lae_test) #deleting all the rows with missing values in Laegern test set
```

```{r}
FLX_Lae_train<- stats::na.omit(FLX_Lae_train) #deleting all the rows with missing values in Laegern train set
```



### Defining the recipes of the models for the train datasets (Davos and Laegern)

```{r}
model_dav_train <- recipes::recipe(GPP_NT_VUT_REF ~ SW_IN_F + VPD_F + PA_F + WS_F + TA_F, 
                      data = FLX_Dav_train) |> #recipe for the model of the Davos dataset
  recipes::step_center(all_numeric(), -all_outcomes()) |>
  recipes::step_scale(all_numeric(), -all_outcomes())
```

```{r}
model_Lae_train <- recipes::recipe(GPP_NT_VUT_REF ~ SW_IN_F + VPD_F + PA_F + WS_F + TA_F, 
                      data = FLX_Lae_train) |> #recipe for the model of the Davos dataset
  recipes::step_center(all_numeric(), -all_outcomes()) |>
  recipes::step_scale(all_numeric(), -all_outcomes())
```


### Using the caret function to determine the best model with maschine learning for Davos
```{r}
# training the best knn model with the Davos train data
library(tidyverse)
library(recipes)
set.seed(1982)
caret_dav_train_knn <- caret::train(model_dav_train, 
                       data = FLX_Dav_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")
```

```{r}
# training the best lm model with the Davos train data
caret_dav_train_lm <- caret::train(model_dav_train, 
  data = FLX_Dav_train |> drop_na(),  # drop missing values
  trControl = caret::trainControl(method = "none"), # no resampling
  method = "lm"
)
```

### loading functions from .R file

```{r}
source("../functions/large_files_ex_6.R") #loading all the large code chunks form another .R file
```

### Within-site validation for Davos models
```{r}
eval_model(mod = caret_dav_train_knn, df_train = FLX_Dav_train, df_test = FLX_Dav_test) # within-site validation knn model davos
```

```{r}
eval_model(mod = caret_dav_train_lm, df_train = FLX_Dav_train, df_test = FLX_Dav_test) #within site validation for Davos lm model 
```

### Using the caret function to determine the best model with maschine learning for Laegern   

```{r}
# training the best knn model with the Laegern train data
library(tidyverse)
library(recipes)
set.seed(1982)
caret_Lae_train_knn <- caret::train(model_Lae_train, 
                       data = FLX_Lae_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")
```


```{r}
# training the best lm model with the Laegern train data
caret_Lae_train_lm <- caret::train(model_Lae_train, 
  data = FLX_Lae_train |> drop_na(),  # drop missing values
  trControl = caret::trainControl(method = "none"), # no resampling
  method = "lm"
)
```

### Within-site validation for Laegern models
```{r}
eval_model(mod = caret_Lae_train_knn, df_train = FLX_Lae_train, df_test = FLX_Lae_test) #within-site validation laegern knn model 
```
```{r}
eval_model(mod = caret_Lae_train_lm, df_train = FLX_Lae_train, df_test = FLX_Lae_test) #within-site validation of Laegern lm model 
```

### Across site validation for Davos models 

```{r}
eval_model(mod = caret_dav_train_knn, df_train = FLX_Dav_train, df_test = FLX_Lae_test) # across-site validation for Davos knn model
```

```{r}
eval_model(mod = caret_dav_train_lm, df_train = FLX_Dav_train, df_test = FLX_Lae_test) # across-site validation for davos lm model
```
### Across site validation for Laegern models

```{r}
eval_model(mod = caret_Lae_train_knn, df_train = FLX_Lae_train, df_test = FLX_Dav_test) #across-site validation for Laegern knn model
```

```{r}
eval_model(mod = caret_Lae_train_lm, df_train = FLX_Lae_train, df_test = FLX_Dav_test) # Across-site validation for Laegern lm model
```





### Pooling the dataframes together (each one for train and test)

```{r}
library(base)
bind_FLX_train <- rbind(FLX_Lae_train, FLX_Dav_train)
```

```{r}
library(base)
bind_FLX_test <- rbind(FLX_Lae_test, FLX_Dav_test)
```


### Building a recipe for the pooled model
```{r}
model_combined_train <- recipes::recipe(GPP_NT_VUT_REF ~ SW_IN_F + VPD_F + PA_F + WS_F + TA_F, 
                      data = bind_FLX_train) |> #recipe for the model of the Davos dataset
  recipes::step_center(all_numeric(), -all_outcomes()) |>
  recipes::step_scale(all_numeric(), -all_outcomes())
```
### Training a knn model with the pooled dataset
As only one model should be trained, i chose to do the knn model as it is a bit more prone to overfitting and i therefore hope for more generalisable results.

```{r}
# training the best knn model with the pooled train data
library(tidyverse)
library(recipes)
set.seed(1982)
caret_combined_train_knn <- caret::train(model_combined_train, 
                       data = bind_FLX_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")
```

### within site evaluation of the pooled data
```{r}
eval_model(mod = caret_combined_train_knn, df_train = bind_FLX_train, df_test = bind_FLX_test) #within site validation for the knn model of the pooled data
```



